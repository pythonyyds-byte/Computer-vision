{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a0c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "from mindspore import  Tensor\n",
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits\n",
    "from mindspore.train.serialization import export\n",
    "from lenet import LeNet5\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms as C\n",
    "import mindspore.dataset.vision as CV\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import Callback\n",
    "\n",
    "#数据集创建\n",
    "def create_dataset(dataset_path,batch_size=256,resize=(32, 32), rescale=1 / 255, shift=-0.5, buffer_size=1000):\n",
    "    dataset = ds.MnistDataset(dataset_path)\n",
    "    # 改变形状\n",
    "    resize_op = CV.Resize(resize)\n",
    "    # 归一化和标准化操作\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    # 变换格式\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "\n",
    "    # 利用map操作对原数据集进行调整\n",
    "    dataset = dataset.map(input_columns=\"image\", operations=[resize_op, rescale_op, hwc2chw_op])\n",
    "    dataset = dataset.map(input_columns=\"label\", operations=C.TypeCast(ms.int32))\n",
    "    # 数据集打乱\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    # 设定batch_size，并丢弃不够一个batch的数据\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "#超参数字典\n",
    "class Config(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "# 设置日志格式\n",
    "def set_logging(config):\n",
    "    if not os.path.exists(config.log_path):\n",
    "        os.makedirs(config.log_path)\n",
    "    filename = os.path.join(config.log_path, config.log_file)\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        filename=filename,\n",
    "        filemode='w',\n",
    "        format='[%(asctime)s %(levelname)-8s] %(message)s',\n",
    "        datefmt='%Y%m%d %H:%M:%S'\n",
    "    )\n",
    "\n",
    "#自定义回调函数，保存训练数据\n",
    "class StepLossAccInfo(Callback):\n",
    "    def __init__(self, model,epoch):\n",
    "        self.model = model\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def on_train_step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        cur_epoch = cb_params.cur_epoch_num\n",
    "        cur_step = (cur_epoch - 1) * 1875 + cb_params.cur_step_num\n",
    "        if cur_step%train_data.get_dataset_size()==0:\n",
    "            self.train_loss = (str(cb_params.net_outputs))\n",
    "            logging.info('======================================================================================')\n",
    "            logging.info('===============================Train - Epoch :{} / Loss:{} =============================='.format(self.epoch + 1, self.train_loss))\n",
    "            logging.info('======================================================================================')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #超参数字典\n",
    "    config = Config({\n",
    "        #数据集名称及路径\n",
    "        \"dataset_name\": \"MNIST\",\n",
    "        \"train_path\": \"D:/data/MNIST/train\",\n",
    "        \"test_path\": \"D:/data/MNIST/test\",\n",
    "\n",
    "        #批处理大小\n",
    "        \"batch_size\": 256,\n",
    "        #学习率\n",
    "        \"learning_rate\": 2e-3,\n",
    "        #周期数\n",
    "        \"n_epoch\": 5,\n",
    "        #测试频率\n",
    "        \"test_freq\": 1, #1即为1周期进行一次测试\n",
    "        #日志路径和模型保存路径\n",
    "        \"model_name\": \"LeNet-5\",\n",
    "        \"onnx_path\": \"./output/models/\",\n",
    "        \"log_path\": \"./output/log/\",\n",
    "    })\n",
    "\n",
    "    #模型保存路径创建\n",
    "    config.onnx_path = os.path.join(config.onnx_path, config.model_name)\n",
    "    if not os.path.exists(config.onnx_path):\n",
    "        os.makedirs(config.onnx_path)\n",
    "    # 日志文件\n",
    "    config.log_file = config.model_name + \".log\"\n",
    "    set_logging(config)\n",
    "    logging.info(config)\n",
    "    #数据集\n",
    "    train_data = create_dataset(config.train_path,batch_size=config.batch_size)\n",
    "    test_data = create_dataset(config.test_path,batch_size=config.batch_size)\n",
    "    #网络模型\n",
    "    net = LeNet5()\n",
    "    #交叉熵损失函数\n",
    "    criterion = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    # 优化器\n",
    "    optimizer = nn.Adam(params=net.trainable_params(), learning_rate=config.learning_rate)\n",
    "    #模型和优化器，损失函数链接在一起\n",
    "    model = Model(net, loss_fn=criterion, optimizer=optimizer, metrics={'accuracy': Accuracy()})\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(config.n_epoch):\n",
    "        #训练阶段\n",
    "        start_time = time.time()\n",
    "        logging.info('\\n')\n",
    "        logging.info('Running training epoch {}'.format(epoch + 1))\n",
    "        #开始训练\n",
    "        model.train(1, train_data, callbacks=[StepLossAccInfo(model,epoch)], dataset_sink_mode=False)\n",
    "\n",
    "        #根据周期数和测试频率进行测试阶段\n",
    "        if (epoch + 1) % config.test_freq == 0:\n",
    "            logging.info('Starting test...')\n",
    "            logging.info('Running testing in epoch {}'.format(epoch + 1))\n",
    "            #开始测试\n",
    "            acc = model.eval(test_data)\n",
    "\n",
    "            logging.info('======================================================================================')\n",
    "            logging.info('===========================Test - Epoch :{} / Accuracy: {}============================'.format(epoch+1,acc['accuracy']))\n",
    "            logging.info('======================================================================================')\n",
    "\n",
    "            logging.info('Test done...')\n",
    "            #保存模型\n",
    "            model_save_path = config.onnx_path + '/lenet-5-epoch' + str(epoch + 1) + '.onnx'\n",
    "            logging.info('Saving weights and model of epoch{}, path:{}'.format(epoch + 1, model_save_path))\n",
    "            export(net, Tensor(np.zeros((1, 1, 32, 32)).astype(np.float32)),file_name=model_save_path, file_format='ONNX')\n",
    "        logging.info('Epoch {} done. Time: {:.2}s'.format(epoch + 1, (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baeb8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}